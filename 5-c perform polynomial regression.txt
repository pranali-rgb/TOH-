import numpy as np
import matplotlib.pyplot as plt

from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression 
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Generating some example data
X = np.array ([1, 2,3, 4, 5]).reshape (-1, 1) # Feature variable
Y = np.array ([1, 4, 9, 16, 25]) # Target variable

# splitting data into training and testing sets
X_train, X_test, Y_train,Y_test = train_test_split(x, Y, test_size=0.2, random_state=42)

# Creating a PolynomialFeatures object with degree=2 (quadratic)
poly = PolynomialFeatures (degree=2)
X_poly_train = poly.fit_transform(X_train)
X_poly_test = poly. transform(X_test)

# Initializing and training the model
model = LinearRegression ()
model.fit(X_poly_train, Y_train)

# Predicting on the test set
Y_poly_pred = model.predict (X_poly_test)

# Printing the model coefficients
print(f"Intercept: {model.intercept_}")
print(f"Coefficients: {model.coef_}")

# Evaluating the model (Mean Squared Error)
mse = mean_squared_error (Y_test, Y_poly_pred)
print (f"Mean Squared Error: {mse}")

# Plotting the data and the polynomial regression curve
plt.scatter(X, Y, color='blue', label='Data points')
plt.plot(X, model.predict(poly.transform(X)), color='red', label='Polynomial Regression Curve')
plt.xlabel('X')
plt.ylabel('Y')
plt.legend()
plt. show()